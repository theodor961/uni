{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e4XIu8oqSfw8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMD56IiXSlUm",
        "outputId": "29371102-3569-458b-f5f8-10df5adfa0c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100%|██████████| 104M/104M [00:04<00:00, 25.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained Inception V3 model\n",
        "model = models.inception_v3(pretrained=True).to(device)\n",
        "model.aux_logits = False\n",
        "# Freeze pre-trained layers\n",
        "#for param in model.parameters():\n",
        "#    param.requires_grad = False\n",
        "\n",
        "# Print layer names and their parameters\n",
        "#for name, param in model.named_parameters():\n",
        "#    print(f\"Layer: {name}, Parameters: {param.size()}\")\n",
        "\n",
        "'''for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name}, Parameters: {param.size()}\")\n",
        "    param.requires_grad = False #to freeze\n",
        "# Replace auxiliary classifier (optional)\n",
        "if hasattr(model, 'AuxLogits'):\n",
        "    in_features_aux = model.AuxLogits.fc.in_features\n",
        "    model.AuxLogits.fc = nn.Linear(in_features_aux, num_classes)\n",
        "# Modify the final fully connected layer for CIFAR-100\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 100, device=device)  # Change the output size to 100 classes\n",
        "\n",
        "# Access a specific layer by name\n",
        "specific_layer = getattr(model, 'layer_name')\n",
        "# Replace with a new Linear layer\n",
        "new_linear_layer = nn.Linear(new_in_features, new_out_features)\n",
        "setattr(model, 'layer_name', new_linear_layer)\n",
        "# Remove a layer\n",
        "delattr(model, 'layer_name')\n",
        "# Add a new layer\n",
        "new_layer = nn.Linear(new_in_features, new_out_features)\n",
        "setattr(model, 'new_layer_name', new_layer)\n",
        "'''\n",
        "\n",
        "# Modify the final fully connected layer for CIFAR-100\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 100, device=device)  # Change the output size to 100 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DEsj2PC6SuqN"
      },
      "outputs": [],
      "source": [
        "# Add more layers at the end\n",
        "class ExtendedInceptionV3(nn.Module):\n",
        "    def __init__(self, base_model):\n",
        "        super(ExtendedInceptionV3, self).__init__()\n",
        "        self.base_model = base_model  # Pre-trained Inception V3\n",
        "        self.additional_layers = nn.Sequential(\n",
        "            nn.Linear(100, 50),  # Example: Add a linear layer with 50 output features\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(50, 100)  # Example: Add another linear layer with 10 output features\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        x = self.additional_layers(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX7TR4LDS071",
        "outputId": "4ae555f6-b745-468a-ce84-06ce7d131a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:13<00:00, 12892050.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the extended model\n",
        "extended_model = ExtendedInceptionV3(model).to(device)\n",
        "\n",
        "# Define data transformations (same as before)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(299),\n",
        "    transforms.CenterCrop(299),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nTlmVo3iS7UV"
      },
      "outputs": [],
      "source": [
        "# Create data loaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(extended_model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LhXErdGTER-",
        "outputId": "ff2f8925-ccd7-4a22-b132-a530866f1189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/2, Batch 0/782, Loss: 4.5914\n",
            "Epoch 0/2, Batch 100/782, Loss: 4.6154\n",
            "Epoch 0/2, Batch 200/782, Loss: 4.6134\n",
            "Epoch 0/2, Batch 300/782, Loss: 4.5840\n",
            "Epoch 0/2, Batch 400/782, Loss: 4.5859\n",
            "Epoch 0/2, Batch 500/782, Loss: 4.5868\n",
            "Epoch 0/2, Batch 600/782, Loss: 4.5621\n",
            "Epoch 0/2, Batch 700/782, Loss: 4.5439\n",
            "Epoch 1/2, Loss: 4.5858\n",
            "Epoch 1/2, Batch 0/782, Loss: 4.5208\n",
            "Epoch 1/2, Batch 100/782, Loss: 4.5062\n",
            "Epoch 1/2, Batch 200/782, Loss: 4.4508\n",
            "Epoch 1/2, Batch 300/782, Loss: 4.4511\n",
            "Epoch 1/2, Batch 400/782, Loss: 4.2495\n",
            "Epoch 1/2, Batch 500/782, Loss: 4.2046\n",
            "Epoch 1/2, Batch 600/782, Loss: 4.1378\n",
            "Epoch 1/2, Batch 700/782, Loss: 3.9827\n",
            "Epoch 2/2, Loss: 4.2451\n"
          ]
        }
      ],
      "source": [
        "# Train the extended model\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "    extended_model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = extended_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        # Print training information\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"Epoch {epoch}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AKFSlKTzTFFl"
      },
      "outputs": [],
      "source": [
        "# Save the trained model (optional)\n",
        "torch.save(extended_model.state_dict(), 'extended_inception_withoutfreeze.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgJ6K9XESgyu",
        "outputId": "ab887095-5549-44c4-b193-d2d3b7a66495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 0.2404\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on the test set\n",
        "extended_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = extended_model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy on the test set: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-snpMag_PsUa",
        "outputId": "0c07484c-7649-440b-b119-12c4cae028f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the train set: 0.2435\n"
          ]
        }
      ],
      "source": [
        "extended_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = extended_model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy on the train set: {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}