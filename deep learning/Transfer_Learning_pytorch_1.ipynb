{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "#we finetune the inception v3 model by only changing the last layer\n",
    "#and freezing all the other layers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "id": "K6a6DNCVy6ju"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Load the Inception model (visual representation below)\n",
    "#The inception_v3 model in torchvision is pretrained on the ImageNet dataset.\n",
    "#ImageNet is a large-scale dataset for image classification, containing over a million labeled images across 1000 classes.\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "d = torch.cuda.is_available()\n",
    "if d==True:\n",
    "    print(\"Torch on GPU available\")\n",
    "    print(f\"GPU {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "model = models.inception_v3(pretrained=True).to(device)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "myQ5-H0qy8Pc",
    "outputId": "ffd752fe-9a0b-4fbb-8d3c-0a3d0ae00059"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Torch on GPU available\n",
      "GPU Tesla T4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "100%|██████████| 104M/104M [00:01<00:00, 103MB/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# [Image of Inception v3 architecture]\n",
    "\n",
    "# 2. Freeze the pre-trained layers (preventing their weights from being updated)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.aux_logits = False"
   ],
   "metadata": {
    "id": "8kfwGPpLzAbU"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. Replace the final fully connected layer with a new one for your task\n",
    "# Modify the final fully connected layer for CIFAR-100 (100 classes)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 100,device=device)  # Change the output size to 100 classes\n"
   ],
   "metadata": {
    "id": "-cp074oLzEIM"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 4. Define data transformations (visual examples included)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(299),  # Resize to Inception's input size\n",
    "    transforms.CenterCrop(299),  # Center crop for consistency\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize to ImageNet stats\n",
    "])\n"
   ],
   "metadata": {
    "id": "rEsrRnU6zG5U"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 5. Load your dataset\n",
    "# Load CIFAR-100 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='/content/drive/MyDrive/Colab Notebooks/Transfer_Learning', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='/content/drive/MyDrive/Colab Notebooks/Transfer_Learning', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTXYMPmkzKWM",
    "outputId": "83bd3690-a2fd-44ce-d17c-4a66347a69b7"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 6. Define loss function and optimizer\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "id": "aRT0Q6_2zMwk"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#model.train()\n",
    "# 7. Train the model\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        #outputs,_ = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # Print training information\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
   ],
   "metadata": {
    "id": "ZCmMy0ydzRxc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1e2ceee2-f1c9-4252-e90c-3f0efa5ec2bb"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/1, Batch 0/782, Loss: 4.6089\n",
      "Epoch 0/1, Batch 100/782, Loss: 4.5024\n",
      "Epoch 0/1, Batch 200/782, Loss: 4.4082\n",
      "Epoch 0/1, Batch 300/782, Loss: 4.3149\n",
      "Epoch 0/1, Batch 400/782, Loss: 4.1723\n",
      "Epoch 0/1, Batch 500/782, Loss: 4.1046\n",
      "Epoch 0/1, Batch 600/782, Loss: 3.9452\n",
      "Epoch 0/1, Batch 700/782, Loss: 3.9481\n",
      "Epoch 1/1, Loss: 4.2291\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "jpGSIG8u2fTC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vZOoerETyUfV",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "66bafce8-983f-4f43-ae48-a24c7bb7180c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch 0/782, Loss: 3.8975\n",
      "Batch 100/782, Loss: 3.7544\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of the model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "    for batch_idx,(inputs, labels) in enumerate(test_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        loss = criterion(outputs, labels)  # Use the same criterion as during training\n",
    "        test_loss += loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "    epoch_loss = running_loss / len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy = correct / total\n",
    "print(f\"Accuracy on the test set: {accuracy:.4f}\")\n",
    "print(f'Test Accuracy: {100 * accuracy:.2f}%')\n",
    "print(f'Test Loss: {test_loss}')"
   ],
   "metadata": {
    "id": "4Xzd5weWI2Vr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8a8503f9-cff2-46a0-a95a-75778c722b3a"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy on the test set: 0.2880\n",
      "Test Accuracy: 28.80%\n",
      "Test Loss: 603.6114099025726\n"
     ]
    }
   ]
  }
 ]
}